# Поиск изображения по текстовому запросу

Проект посвящён созданию модели, которая определяет соответствие между текстом и изображением. Цель — научиться сопоставлять запрос пользователя и фотографию, чтобы улучшить поиск изображений и рекомендации.

---

## Цели исследования

- Изучить структуру данных: текстовые запросы, изображения, экспертные и крауд‑оценки.  
- Выполнить исследовательский анализ: выявить шум, дисбаланс, ненадёжные оценки.  
- Подготовить данные: обработать тексты, извлечь визуальные и текстовые эмбеддинги.  
- Построить векторные представления изображений (ResNet / EfficientNet / CLIP).  
- Построить текстовые эмбеддинги (TF‑IDF / SBERT / CLIP‑text).  
- Обучить модель для предсказания соответствия «текст → картинка».  
- Добиться устойчивого качества на тестовой выборке.  

---

## Данные

Используются файлы:

### `train_dataset.csv`
Содержит пары:  
- `img_id` — идентификатор изображения  
- `text` — текстовый запрос  
- `rate_1`, `rate_2`, `rate_3` — оценки трёх экспертов  
- `crowd_rates` — данные краудсорсинга  

### `train_images/`
Папка с изображениями для обучения.

### `test_images/`
Папка с изображениями для тестирования.

### Целевая переменная
Формируется на основе:  
- экспертных оценок,  
- данных крауда,  
- агрегированного показателя соответствия в диапазоне **0–1**.

---

## Основные выводы

- Данные требуют тщательной очистки из‑за шума в оценках.  
- Использование CLIP позволяет автоматически связать текст и картинку в общем пространстве.  
- Финальная модель хорошо решает задачу сопоставления и подходит для системы поиска изображений по запросу.  
- Текстовые и визуальные признаки вместе дают максимальное качество.  

---

## Используемый стек

- Python  
- pandas, NumPy  
- matplotlib, seaborn  
- nltk, spacy  
- PyTorch  
- sklearn  
- PIL, OpenCV  


