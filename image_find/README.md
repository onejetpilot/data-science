# Поиск изображения по текстовому запросу

Проект посвящён созданию модели, которая определяет соответствие между текстом и изображением. Цель — научиться сопоставлять запрос пользователя и фотографию, чтобы улучшить поиск изображений и рекомендации.

---

## Цели исследования

- Изучить структуру данных: текстовые запросы, изображения, экспертные и крауд‑оценки.  
- Выполнить исследовательский анализ: выявить шум, дисбаланс, ненадёжные оценки.  
- Подготовить данные: обработать тексты, извлечь визуальные и текстовые эмбеддинги.  
- Построить векторные представления изображений (ResNet / EfficientNet / CLIP).  
- Построить текстовые эмбеддинги (TF‑IDF / SBERT / CLIP‑text).  
- Обучить модель для предсказания соответствия «текст → картинка».  
- Добиться устойчивого качества на тестовой выборке.  

---

## Данные

Используются файлы:

### `train_dataset.csv`
Содержит пары:  
- `img_id` — идентификатор изображения  
- `text` — текстовый запрос  
- `rate_1`, `rate_2`, `rate_3` — оценки трёх экспертов  
- `crowd_rates` — данные краудсорсинга  

### `train_images/`
Папка с изображениями для обучения.

### `test_images/`
Папка с изображениями для тестирования.

### Целевая переменная
Формируется на основе:  
- экспертных оценок,  
- данных крауда,  
- агрегированного показателя соответствия в диапазоне **0–1**.

---

## Предобработка данных

Выполнены шаги:

- загрузка и объединение всех источников данных;  
- анализ оценок экспертов → удаление противоречивых случаев;  
- анализ крауда → фильтрация крайне шумных меток;  
- финальная разметка через агрегированную метрику (например, `(rate_1 + rate_2 + rate_3)/3`);  
- очистка текстов:  
  - приведение к нижнему регистру,  
  - удаление спецсимволов,  
  - лемматизация,  
  - удаление стоп‑слов;  
- удаление редких и нерелевантных текстов;  
- удаление изображений с ошибками чтения.

---

## Исследовательский анализ данных

По данным экспертов:

- оценки экспертов скошены в сторону соответствия;  
- много оценок «1» и «2» → тексты часто хорошо описывают изображение;  
- ~58% случаев — полное совпадение оценок всех трёх экспертов.

По данным крауда:

- большинство оценок — отрицательные;  
- используется очищение через пороги:  
  - `share_confirmed ≥ 0.8` → соответствие;  
  - `share_confirmed ≤ 0.2` → несоответствие.

По текстам:

- тексты короткие, предметные;  
- много однотипных ключевых слов;  
- требуется качественная обработка для получения хороших эмбеддингов.

По изображениям:

- фотографии разнообразные по содержимому;  
- часть изображений содержит текстовые элементы;  
- изображения разных размеров приведены к единому формату.

---

## Извлечение признаков

### Текстовые эмбеддинги
Использованы варианты:

- TF‑IDF  
- Word2Vec / FastText  
- **SBERT**  
- CLIP‑text encoder

Наилучшие результаты дают модели, учитывающие семантику (SBERT, CLIP).

### Визуальные эмбеддинги

Использованы предобученные сети:

- ResNet50  
- EfficientNet-B0  
- **CLIP‑vision encoder**

Качество модели существенно выше при использовании CLIP, так как обучен именно на задаче сопоставления текста и изображения.

---

## Обучение модели

После получения текстовых и визуальных эмбеддингов обучена модель на их комбинации:

Методы:

- Логистическая регрессия  
- RandomForest  
- LightGBM  
- CatBoost  
- **MLP-классификатор / Head‑слой CLIP**  
- Cosine Similarity Baseline

Финальный вариант:

- объединение текстового и визуального пространства;  
- оптимизация под косинусную близость;  
- порог для классификации подобран по F1.

---

## Качество модели

Модель показывает устойчивые результаты:

- высокая точность определения соответствия;  
- корректная работа на новых изображениях;  
- стабильность предсказаний при разных типах запросов.

Лучшие результаты достигнуты при использовании эмбеддингов **CLIP (text + image)**.

---

## Основные выводы

- Данные требуют тщательной очистки из‑за шума в оценках.  
- Использование CLIP позволяет автоматически связать текст и картинку в общем пространстве.  
- Финальная модель хорошо решает задачу сопоставления и подходит для системы поиска изображений по запросу.  
- Текстовые и визуальные признаки вместе дают максимальное качество.  

---

## Используемый стек

- Python  
- pandas, NumPy  
- matplotlib, seaborn  
- nltk, spacy  
- PyTorch  
- sklearn  
- PIL, OpenCV  

