# Поиск изображения по текстовому запросу

Проект посвящён созданию модели, которая определяет соответствие между текстом и изображением. Цель — научиться сопоставлять запрос пользователя и фотографию, чтобы улучшить поиск изображений и рекомендации.

## Используемый стек

![Python](https://img.shields.io/badge/-Python-blue) ![Pandas](https://img.shields.io/badge/-Pandas-blue) ![NumPy](https://img.shields.io/badge/-NumPy-yellow) ![Matplotlib](https://img.shields.io/badge/-Matplotlib-orange) ![Seaborn](https://img.shields.io/badge/-Seaborn-lightblue) ![NLTK](https://img.shields.io/badge/-NLTK-green) ![spaCy](https://img.shields.io/badge/-spaCy-lightblue) ![PyTorch](https://img.shields.io/badge/-PyTorch-red) ![PIL](https://img.shields.io/badge/-PIL-lightgrey) ![OpenCV](https://img.shields.io/badge/-OpenCV-blue)
---

## Цели исследования

- Изучить структуру данных: текстовые запросы, изображения, экспертные и крауд‑оценки.  
- Выполнить исследовательский анализ: выявить шум, дисбаланс, ненадёжные оценки.  
- Подготовить данные: обработать тексты, извлечь визуальные и текстовые эмбеддинги.  
- Построить векторные представления изображений (ResNet / EfficientNet / CLIP).  
- Построить текстовые эмбеддинги (TF‑IDF / SBERT / CLIP‑text).  
- Обучить модель для предсказания соответствия «текст → картинка».  
- Добиться устойчивого качества на тестовой выборке.  

---

## Данные

Используются файлы:

### `train_dataset.csv`
Содержит пары:  
- `img_id` — идентификатор изображения  
- `text` — текстовый запрос  
- `rate_1`, `rate_2`, `rate_3` — оценки трёх экспертов  
- `crowd_rates` — данные краудсорсинга  

### `train_images/`
Папка с изображениями для обучения.

### `test_images/`
Папка с изображениями для тестирования.

### Целевая переменная
Формируется на основе:  
- экспертных оценок,  
- данных крауда,  
- агрегированного показателя соответствия в диапазоне **0–1**.

---

## Основные выводы

- Данные требуют тщательной очистки из‑за шума в оценках.  
- Использование CLIP позволяет автоматически связать текст и картинку в общем пространстве.  
- Финальная модель хорошо решает задачу сопоставления и подходит для системы поиска изображений по запросу.  
- Текстовые и визуальные признаки вместе дают максимальное качество.  


