# Классификация токсичных комментариев (NLP)

Проект посвящён созданию модели, определяющей токсичность пользовательских сообщений.  
Задача — автоматизировать модерацию контента и выявлять оскорбительные или агрессивные комментарии.

---

## Цель исследования

- Очистить текстовые данные
- Построить векторизацию (TF-IDF / Word2Vec / SBERT)
- Обучить несколько моделей классификации
- Выбрать лучшую модель по метрике F1
- Интерпретировать результаты

---

## Данные

Использовались данные с комментариями, в которых содержится:

- `text` — текст сообщения  
- `toxic` — целевой признак (1 — токсично, 0 — нет)

---

## Подготовка данных

Выполнено:

Подготовили данные для обучения — выполнили очистку, лемматизацию, удаление стоп-слов, разделили датасет на train/test и представили тексты в виде TF-IDF матрицы признаков, готовой для обучения.

Частотный анализ показал, что токсичные комментарии опираются на ограниченный набор повторяющихся слов, тогда как нетоксичные более разнообразны по лексике. 

Сравнение облаков слов показало резкий контраст
- токсичные комментарии концентрируются вокруг грубых оскорблений
- нетоксичные комментарии наполнены словами, связанными с обсуждением и редактированием

---

## Методы векторизации

Использовались способы представления текстов:

- **TF-IDF**  

---

## Модели

Были обучены следующие модели:

- Logistic Regression    
- SVC  

---

## Финальные метрики

| Модель                  | F1-score | 
|-------------------------|----------|
| LogReg + TFIDF          | 0.7519   |
| SVC  + TF-IDF           | 0.7569   | 

> **Лучшая модель:** *LinearSVC*  
> **Финальный F1-score:** *0.7563*  

---

## Используемый стек

**Язык и базовые библиотеки:**
- Python
- pandas
- NumPy

**ML и векторизация:**
- scikit-learn (LogisticRegression, LinearSVC, TfidfVectorizer, GridSearchCV, StratifiedKFold и др.)
- LightGBM (LGBMClassifier)

**NLP и предобработка текста:**
- регулярные выражения (`re`)
- NLTK (WordNetLemmatizer, стоп-слова)
- spaCy
- WordCloud

**Визуализация:**
- Matplotlib
- Seaborn

---

## Выводы

Модель LinearSVC показала итоговую метрику F1 = 0.7563, что превышает минимальное требование задачи (F1 ≥ 0.75).
- Для нетоксичных комментариев (класс 0) качество очень высокое: precision = 0.981, recall = 0.957, f1 = 0.969.
- Для токсичных комментариев (класс 1) показатели ниже, но приемлемые: precision = 0.689, recall = 0.839, f1 = 0.756. Это значит, что модель чаще находит токсичные комментарии (высокий recall), но иногда ошибочно относит нетоксичные к токсичным.

---

