# Классификация токсичных комментариев

Проект направлен на разработку модели, способной автоматически определять токсичность пользовательских комментариев. Такая система может использоваться в службах модерации, сервисах с пользовательским контентом и в автоматических фильтрах качества коммуникации.

---

## Цели исследования
- Проанализировать корпус текстов и выявить особенности токсичных и нетоксичных комментариев.  
- Подготовить данные: очистить, нормализовать и лемматизировать текст.  
- Исследовать лексическое различие между классами.  
- Сформировать признаковое пространство на основе TF-IDF.  
- Обучить и сравнить несколько моделей.  
- Выбрать финальную модель, удовлетворяющую требованию F1 ≥ 0.75.  

---

## Данные
Исходный датасет содержит:
- **159 292** комментария,  
- столбцы: `text` (текст комментария), `toxic` (целевой признак: токсичность),  
- пропуски и дубликаты отсутствуют.

Выборка выраженно несбалансирована: большинство комментариев относятся к классу 0 (нетоксичные).

---

## Основные выводы
- Данные успешно подготовлены: выполнена очистка, нормализация и лемматизация.  
- Токсичные комментарии действительно имеют ограниченную лексику и содержат ярко выраженные оскорбления.  
- Наиболее информативным способом представления текстов стала TF-IDF матрица с 1–2-граммами.  
- Сравнение моделей показало, что LinearSVC лучше всего справляется с задачей.  
- Итоговый F1 превышает требуемый уровень, что позволяет использовать модель в реальных задачах фильтрации токсичности.

---

## Используемый стек
- Python  
- Pandas, NumPy  
- Matplotlib, Seaborn  
- spaCy  
- NLTK  
- WordCloud  
- Scikit-learn (TfidfVectorizer, LogisticRegression, LinearSVC, StratifiedKFold, cross-validation tools)  
- Регулярные выражения (`re`)
